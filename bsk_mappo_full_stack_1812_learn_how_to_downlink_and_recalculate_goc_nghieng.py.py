import math
import gc
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import sys
import os

# --- 1. BASILISK IMPORTS ---
try:
    from Basilisk.utilities import SimulationBaseClass, macros, simIncludeGravBody, orbitalMotion, vizSupport, simIncludeRW
    from Basilisk.simulation import spacecraft, reactionWheelStateEffector
    from Basilisk.simulation import extForceTorque # Ch·ªâ d√πng ExtForce, t·∫Øt Drag/Atmo ƒë·ªÉ an to√†n
    from Basilisk.architecture import messaging 
    BASILISK_AVAILABLE = True
    print("[INIT] Basilisk libraries loaded.")
except ImportError:
    print("[ERROR] Basilisk not found.")
    sys.exit(1)

# --- 2. MAPPO NETWORK (CTDE) ---
class MultiAgentActorCritic(nn.Module):
    def __init__(self, obs_dim, global_state_dim, action_dim, hidden=256):
        super().__init__()
        # Actor: Obs c·ª•c b·ªô -> Action
        self.actor = nn.Sequential(
            nn.Linear(obs_dim, hidden),
            nn.Tanh(),
            nn.Linear(hidden, hidden),
            nn.Tanh(),
            nn.Linear(hidden, action_dim)
        )
        # Critic: Global State -> Value
        self.critic = nn.Sequential(
            nn.Linear(global_state_dim, hidden),
            nn.Tanh(),
            nn.Linear(hidden, hidden),
            nn.Tanh(),
            nn.Linear(hidden, 1)
        )

    def act(self, obs):
        return self.actor(obs)

    def evaluate(self, global_state):
        return self.critic(global_state)

# --- 3. MULTI-AGENT ENVIRONMENT (N√ÇNG C·∫§P) ---
class BasiliskFullMissionEnv:
    def __init__(self, n_sats=4, n_targets=50, decision_dt=10.0, viz=False):
        self.n_sats = n_sats
        self.n_targets = n_targets
        self.decision_dt = decision_dt
        self.viz = viz
        
        # H·∫±ng s·ªë v·∫≠t l√Ω & T√†i nguy√™n
        self.earth_radius = 6371e3
        self.mu = 398600.4418e9
        self.max_slew_rate = math.radians(5.0) 
        self.fuel_max = 200.0
        self.batt_max = 100.0
        self.buffer_max = 5 
        
        # Bi·∫øn theo d√µi to√†n c·ª•c (Global Memory)
        # L∆∞u c√°c ID m·ª•c ti√™u ƒë√£ ƒë∆∞·ª£c ch·ª•p b·ªüi B·∫§T K·ª≤ v·ªá tinh n√†o
        self.global_captured_targets = set()

        # C·∫•u h√¨nh Tr·∫°m M·∫∑t ƒë·∫•t
        self.gs_coords = [
            (21.0285, 105.8542),   # Hanoi
            (40.7128, -74.0060),   # New York
            (51.5074, -0.1278),    # London
            (-33.8688, 151.2093)   # Sydney
        ]
        self.n_gs = len(self.gs_coords)
        self.ORBIT_CHOICES = [10.0, 45.0, 90.0] 
        # ACTION SPACE
        self.ACT_CHARGE = self.n_targets + self.n_gs
        self.ACT_ALT_UP = self.ACT_CHARGE + 1
        self.ACT_ALT_DOWN = self.ACT_CHARGE + 2
        self.ACT_GOTO_INC_START = self.ACT_ALT_DOWN + 1
        self.n_orbit_choices = len(self.ORBIT_CHOICES)
        self.action_dim = self.ACT_GOTO_INC_START + self.n_orbit_choices
        # OBSERVATION SPACE
        self.obs_dim = 14  # [r(3), v(3), fuel(1), batt(1), buffer(1)] = 9
        self.global_state_dim = self.obs_dim * self.n_sats 

        self._build_locations()
        self._init_simulator()

    def _build_locations(self):
        rng = np.random.RandomState(42)
        self.targets_ecef = []
        for _ in range(self.n_targets):
            lat = rng.uniform(-60, 60) * macros.D2R
            lon = rng.uniform(-180, 180) * macros.D2R
            self.targets_ecef.append(self._lld_to_ecef(lat, lon, 0))
            
        self.gs_ecef = []
        for lat_deg, lon_deg in self.gs_coords:
            self.gs_ecef.append(self._lld_to_ecef(lat_deg*macros.D2R, lon_deg*macros.D2R, 0))

    def _lld_to_ecef(self, lat, lon, alt):
        r = self.earth_radius + alt
        x = r * math.cos(lat) * math.cos(lon)
        y = r * math.cos(lat) * math.sin(lon)
        z = r * math.sin(lat)
        return np.array([x, y, z])

    def _cleanup(self):
        if hasattr(self, 'scSim'): self.scSim = None
        gc.collect()
    '''
    def _init_simulator(self):
        self._cleanup()
        self.scSim = SimulationBaseClass.SimBaseClass()
        self.scSim.SetProgressBar(False)
        self.taskName = "dynTask"
        self.dt = macros.sec2nano(2.0) #Xem th·ªùi gian n√†o ph√π h·ª£p
        self.scSim.CreateNewProcess("dynProcess").addTask(self.scSim.CreateNewTask(self.taskName, self.dt))

        self.all_viz_objects = [] 
        self.sats = []
        self.states = []
        
        gravFactory = simIncludeGravBody.gravBodyFactory()
        earth = gravFactory.createEarth(); earth.isCentralBody = True
        self.planet_mu = earth.mu
        
        # --- A. T·∫†O 4 V·ªÜ TINH TH·∫¨T ---
        for i in range(self.n_sats):
            sc = spacecraft.Spacecraft()
            sc.ModelTag = f"Sat_{i}"
            self.scSim.AddModelToTask(self.taskName, sc)
            gravFactory.addBodiesTo(sc)
            
            oe = orbitalMotion.ClassicElements()
            oe.a = 7000e3; oe.e = 0.001; oe.i = 45.0 * macros.D2R
            oe.Omega = (i * 360.0 / self.n_sats) * macros.D2R; oe.omega = 0.0; oe.f = 0.0
            rN, vN = orbitalMotion.elem2rv(self.planet_mu, oe)
            sc.hub.r_CN_NInit = np.array(rN); sc.hub.v_CN_NInit = np.array(vN)
            
            self.sats.append(sc)
            self.all_viz_objects.append(sc)
            
            bore_vec = -np.array(rN) / np.linalg.norm(rN)
            self.states.append({'fuel': self.fuel_max, 'batt': self.batt_max, 'buffer': 0, 'bore_vec': bore_vec})

        # --- B. T·∫†O DUMMY OBJECTS ---
        self.dummy_targets = []
        self.dummy_gs = []

        # 1. Targets (Nh·ªè, Th·∫•p)
        for k, ecef in enumerate(self.targets_ecef):
            dummy = spacecraft.Spacecraft()
            dummy.ModelTag = f"TGT_{k}"
            r_mag = np.linalg.norm(ecef)
            dummy.hub.r_CN_NInit = ecef * ((r_mag + 50000.0) / r_mag)
            self.scSim.AddModelToTask(self.taskName, dummy)
            self.all_viz_objects.append(dummy)
            self.dummy_targets.append(dummy)

        # 2. Ground Stations (To, Cao)
        gs_names = ["Hanoi", "NewYork", "London", "Sydney"]
        for k, ecef in enumerate(self.gs_ecef):
            dummy = spacecraft.Spacecraft()
            dummy.ModelTag = f"GS_{gs_names[k]}" 
            r_mag = np.linalg.norm(ecef)
            dummy.hub.r_CN_NInit = ecef * ((r_mag + 300000.0) / r_mag)
            self.scSim.AddModelToTask(self.taskName, dummy)
            self.all_viz_objects.append(dummy)
            self.dummy_gs.append(dummy)

        # --- C. VIZARD SETUP (Safe Mode) ---
        if self.viz:
            try:
                viz = vizSupport.enableUnityVisualization(self.scSim, self.taskName, self.all_viz_objects, saveFile="mission_sim_final.bin")
                try:
                    if hasattr(vizSupport, 'createStandardCamera'):
                        # Sat: 20 deg
                        for i in range(self.n_sats):
                            vizSupport.createStandardCamera(viz, setMode=1, spacecraftName=f"Sat_{i}", 
                                fieldOfView=20.0*macros.D2R, pointingVector_B=[-1,0,0])
                        # Target: 45 deg
                        for tgt in self.dummy_targets:
                            vizSupport.createStandardCamera(viz, setMode=1, spacecraftName=tgt.ModelTag,
                                fieldOfView=45.0*macros.D2R, pointingVector_B=[0,1,0])
                        # GS: 160 deg
                        for gs in self.dummy_gs:
                            vizSupport.createStandardCamera(viz, setMode=1, spacecraftName=gs.ModelTag,
                                fieldOfView=160.0*macros.D2R, pointingVector_B=[0,1,0])
                except: pass
                
                # M√†u ƒë∆∞·ªùng qu·ªπ ƒë·∫°o (n·∫øu c√≥)
                try:
                    if hasattr(vizSupport, 'setOrbitColor'):
                        for gs in self.dummy_gs: vizSupport.setOrbitColor(viz, spacecraftName=gs.ModelTag, color=[1, 1, 0, 1])
                        for tgt in self.dummy_targets: vizSupport.setOrbitColor(viz, spacecraftName=tgt.ModelTag, color=[1, 0, 0, 1])
                except: pass
                self.vizObj = viz
            except Exception as e: self.vizObj = None

        self.scSim.InitializeSimulation()
        self.sim_time = 0.0
    '''
    def _init_simulator(self):
        self._cleanup()
        self.scSim = SimulationBaseClass.SimBaseClass()
        self.scSim.SetProgressBar(False)
        self.taskName = "dynTask"
        self.dt = macros.sec2nano(1.0)
        self.scSim.CreateNewProcess("dynProcess").addTask(self.scSim.CreateNewTask(self.taskName, self.dt))

        self.all_viz_objects = [] # List g·ª≠i Vizard
        self.sats = []
        self.states = []
        self.force_msgs = []
        self.force_payloads = []
        
        gravFactory = simIncludeGravBody.gravBodyFactory()
        earth = gravFactory.createEarth(); earth.isCentralBody = True
        self.planet_mu = earth.mu
        
        # --- A. T·∫†O V·ªÜ TINH ---
        for i in range(self.n_sats):
            sc = spacecraft.Spacecraft()
            sc.ModelTag = f"Sat_{i}"
            self.scSim.AddModelToTask(self.taskName, sc)
            gravFactory.addBodiesTo(sc)
            
            # Ch·ªâ d√πng ExtForce, kh√¥ng d√πng Drag (Safe Mode)
            extForce = extForceTorque.ExtForceTorque()
            extForce.ModelTag = f"ExtForce_{i}"
            sc.addDynamicEffector(extForce)
            self.scSim.AddModelToTask(self.taskName, extForce)
            
            # [FIX HERE] T·∫°o v√† L∆∞u tr·ªØ Message L·ª±c
            cmdPayload = messaging.CmdForceInertialMsgPayload()
            cmdPayload.forceRequestInertial = [0.0, 0.0, 0.0]
            cmdMsg = messaging.CmdForceInertialMsg().write(cmdPayload)
            extForce.cmdForceInertialInMsg.subscribeTo(cmdMsg)
            
            # ƒê·∫©y v√†o danh s√°ch qu·∫£n l√Ω
            self.force_msgs.append(cmdMsg)
            self.force_payloads.append(cmdPayload)
            
            # Qu·ªπ ƒë·∫°o Walker Delta
            oe = orbitalMotion.ClassicElements()
            oe.a = 7000e3; oe.e = 0.001; oe.i = 45.0 * macros.D2R
            oe.Omega = (i * 360.0 / self.n_sats) * macros.D2R; oe.omega = 0.0; oe.f = 0.0
            rN, vN = orbitalMotion.elem2rv(self.planet_mu, oe)
            
            sc.hub.r_CN_NInit = np.array(rN); sc.hub.v_CN_NInit = np.array(vN)
            self.sats.append(sc)
            self.all_viz_objects.append(sc)
            
            # State m·ªü r·ªông: Th√™m Battery v√† Data Buffer
            bore_vec = -np.array(rN) / np.linalg.norm(rN)
            self.states.append({
                'fuel': self.fuel_max,
                'batt': self.batt_max,      # Pin 100%
                'buffer': 0,                # Ch∆∞a c√≥ ·∫£nh n√†o
                'bore_vec': bore_vec,
                'captured_targets': set()   # ƒê·ªÉ th·ªëng k√™
            })

        # --- B. T·∫†O DUMMY OBJECTS CHO VIZARD (Targets & GS) ---
        self.dummy_objs = []
        
        # 1. Targets (M√†u ƒê·ªè - Red)
        for k, ecef in enumerate(self.targets_ecef):
            dummy = spacecraft.Spacecraft()
            dummy.ModelTag = f"TGT_{k}"
            # N√¢ng cao 50km
            r_mag = np.linalg.norm(ecef)
            dummy.hub.r_CN_NInit = ecef * ((r_mag + 50000.0) / r_mag)
            self.scSim.AddModelToTask(self.taskName, dummy)
            self.all_viz_objects.append(dummy)
            self.dummy_objs.append({'obj': dummy, 'type': 'target'})

        # 2. Ground Stations (M√†u Xanh L√° - Green)
        gs_names = ["Hanoi", "NewYork", "London", "Sydney"]
        for k, ecef in enumerate(self.gs_ecef):
            dummy = spacecraft.Spacecraft()
            dummy.ModelTag = f"GS_{gs_names[k]}"
            # N√¢ng cao 60km (cao h∆°n target x√≠u cho d·ªÖ ph√¢n bi·ªát)
            r_mag = np.linalg.norm(ecef)
            dummy.hub.r_CN_NInit = ecef * ((r_mag + 60000.0) / r_mag)
            self.scSim.AddModelToTask(self.taskName, dummy)
            self.all_viz_objects.append(dummy)
            self.dummy_objs.append({'obj': dummy, 'type': 'gs'})

        # --- C. VIZARD ---
        if self.viz:
            try:
                viz = vizSupport.enableUnityVisualization(self.scSim, self.taskName, self.all_viz_objects, saveFile="mission_sim_learn_how_to_downlink.bin")
                # V·∫Ω camera
                '''
                try:
                    if hasattr(vizSupport, 'createStandardCamera'):
                        for i in range(self.n_sats):
                            vizSupport.createStandardCamera(viz, setMode=1, spacecraftName=f"Sat_{i}", 
                                fieldOfView=30.0*macros.D2R, pointingVector_B=[-1,0,0], position_B=[0,0,0])
                except: pass
                '''
                self.vizObj = viz
                print(f"--- ƒê√£ t·∫°o {self.n_targets} Targets v√† {self.n_gs} GroundStations ---")
            except Exception as e: self.vizObj = None

        self.scSim.InitializeSimulation()
        self.sim_time = 0.0
        
    def reset(self):
        # Reset l·∫°i danh s√°ch Global
        self.global_captured_targets = set()
        self._init_simulator()
        return self._get_all_obs()

    def _get_all_obs(self):
            obs_list = []
            for i, sat in enumerate(self.sats):
                # 1. ƒê·ªçc tr·∫°ng th√°i v·ªá tinh
                stateMsg = sat.scStateOutMsg.read()
                r_sat = np.array(stateMsg.r_BN_N)
                v_sat = np.array(stateMsg.v_BN_N)
                
                # 2. T√¨m Tr·∫°m M·∫∑t ƒê·∫•t (GS) g·∫ßn nh·∫•t
                min_dist = 1e9
                nearest_gs_vec = np.zeros(3)
                
                for gs_pos in self.gs_ecef:
                    # T√≠nh vector t·ª´ V·ªá tinh -> Tr·∫°m
                    rel_vec = gs_pos - r_sat
                    dist = np.linalg.norm(rel_vec)
                    
                    if dist < min_dist:
                        min_dist = dist
                        nearest_gs_vec = rel_vec
                
                # Chu·∫©n h√≥a kho·∫£ng c√°ch (ƒë·ªÉ Neural Net d·ªÖ h·ªçc)
                # Chia cho 10,000km ƒë·ªÉ ƒë∆∞a v·ªÅ kho·∫£ng [0, 1]
                dist_norm = [min_dist / 10000e3] 
                
                # Chu·∫©n h√≥a vector h∆∞·ªõng (Unit Vector)
                if min_dist > 0:
                    dir_norm = nearest_gs_vec / min_dist
                else:
                    dir_norm = [0, 0, 0]

                # 3. T√≠nh g√≥c nghi√™ng (nh∆∞ c≈©)
                try:
                    oe = orbitalMotion.rv2elem(self.planet_mu, r_sat, v_sat)
                    inc_norm = [oe.i / (90.0 * macros.D2R)]
                except: inc_norm = [0.5]
                
                # 4. Gom l·∫°i c√°c th√¥ng s·ªë c≈©
                r_norm = r_sat / 1e7
                v_norm = v_sat / 1e4
                f = [self.states[i]['fuel'] / self.fuel_max]
                b = [self.states[i]['batt'] / self.batt_max]
                d = [self.states[i]['buffer'] / self.buffer_max]
                
                # 5. T·ªîNG H·ª¢P OBSERVATION (14 chi·ªÅu)
                # [Pos(3), Vel(3), Fuel(1), Batt(1), Buffer(1), Inc(1), Dist_GS(1), Dir_GS(3)]
                obs = np.concatenate([
                    r_norm, v_norm, f, b, d, inc_norm, 
                    dist_norm, dir_norm
                ]).astype(np.float32)
                
                obs_list.append(obs)
                
            return obs_list
    
    def step(self, actions, debug_mode=True):
            rewards = np.zeros(self.n_sats)
            dones = [False] * self.n_sats
            current_nano = macros.sec2nano(self.sim_time)
            
            for i, action in enumerate(actions):
                sat = self.sats[i]
                state = self.states[i]
                act = int(action)
                
                # 0. Reset L·ª±c
                self.force_payloads[i].forceRequestInertial = [0.0, 0.0, 0.0]
                self.force_msgs[i].write(self.force_payloads[i], current_nano)

                # Check tr·∫°ng th√°i s·ªëng c√≤n
                # [N√ÇNG C·∫§P] N·∫øu r∆°i xu·ªëng th·∫•p qu√° ho·∫∑c NaN -> Ch·∫øt
                scMsg = sat.scStateOutMsg.read()
                r_curr = np.array(scMsg.r_BN_N)
                v_curr = np.array(scMsg.v_BN_N)
                
                if np.isnan(r_curr).any(): dones[i]=True; continue
                if (np.linalg.norm(r_curr) - self.earth_radius) < 200e3: dones[i]=True; continue
                if state['batt'] <= 0 or state['fuel'] <= 0: rewards[i] -= 10.0; dones[i] = True; continue

                # Vector v·∫≠n t·ªëc
                v_mag = np.linalg.norm(v_curr)
                v_dir = v_curr / (v_mag + 1e-9)

                # -----------------------------------------------------------
                # LOGIC H√ÄNH ƒê·ªòNG
                # -----------------------------------------------------------

                # --- 1. S·∫†C PIN ---
                if act == self.ACT_CHARGE:
                    state['batt'] = min(self.batt_max, state['batt'] + 5.0)
                    rewards[i] += 0.1
                    # N·∫øu Pin ƒë·∫ßy m√† c·ª© S·∫°c m√£i th√¨ c≈©ng ph·∫°t nh·∫π ƒë·ªÉ n√≥ ƒëi l√†m vi·ªác kh√°c
                    if state['batt'] >= self.batt_max: rewards[i] -= 0.1
                    if debug_mode:
                        print(f"[t={self.sim_time:.0f}] ‚ö° Sat {i} CHARGING (+5.0 batt)")

                # --- 2. THAY ƒê·ªîI QU·ª∏ ƒê·∫†O (ALT / GOTO INC) ---
                elif act in [self.ACT_ALT_UP, self.ACT_ALT_DOWN] or \
                    (self.ACT_GOTO_INC_START <= act < self.ACT_GOTO_INC_START + self.n_orbit_choices):
                    
                    # ... (Gi·ªØ nguy√™n logic t√≠nh to√°n l·ª±c ƒë·∫©y nh∆∞ code tr∆∞·ªõc) ...
                    # Copy l·∫°i ph·∫ßn x·ª≠ l√Ω ALT v√† GOTO INC c·ªßa b·∫°n ·ªü ƒë√¢y
                    # V√¨ ph·∫ßn n√†y d√†i n√™n t√¥i vi·∫øt t·∫Øt l√† gi·ªØ nguy√™n ƒë·ªÉ t·∫≠p trung v√†o ph·∫ßn Buffer
                    
                    # [QUAN TR·ªåNG] N·∫øu Buffer ƒë·∫ßy, khuy·∫øn kh√≠ch c√°c h√†nh ƒë·ªông di chuy·ªÉn (ƒë·ªÉ v·ªÅ tr·∫°m)
                    if state['buffer'] >= self.buffer_max:
                        rewards[i] += 0.2 # ƒê·ªông vi√™n vi·ªác di chuy·ªÉn t√¨m ƒë∆∞·ªùng
                        if debug_mode:
                            print(f"[t={self.sim_time:.0f}] üöÄ Sat {i} BUFFER FULL - Encouraged to MOVE!")
                    
                    # (Logic t√≠nh to√°n Force gi·ªØ nguy√™n nh∆∞ c≈©...)
                    # ... Code x·ª≠ l√Ω Force ...
                    # ƒê·ªÉ code ch·∫°y ƒë∆∞·ª£c ngay, t√¥i paste l·∫°i ƒëo·∫°n x·ª≠ l√Ω c∆° b·∫£n:
                    if act in [self.ACT_ALT_UP, self.ACT_ALT_DOWN]:
                        if state['fuel'] >= 1.0:
                            dv_vec = v_dir if act == self.ACT_ALT_UP else -v_dir
                            force_vec = (sat.hub.mHub * 10.0) / self.decision_dt * dv_vec
                            self.force_payloads[i].forceRequestInertial = force_vec.tolist()
                            self.force_msgs[i].write(self.force_payloads[i], current_nano)
                            state['fuel'] -= 1.0; state['batt'] -= 1.0
                            if debug_mode:
                                action_str = "ALT UP" if act == self.ACT_ALT_UP else "ALT DOWN"
                                print(f"[t={self.sim_time:.0f}] üöÄ Sat {i} {action_str} - Fuel -1.0, Batt -1.0")
                    elif self.ACT_GOTO_INC_START <= act:
                        if state['fuel'] >= 5.0:
                            # ... Logic t√≠nh GOTO INC ...
                            # Gi·∫£ s·ª≠ ƒë√£ x·ª≠ l√Ω xong l·ª±c
                            state['fuel'] -= 5.0; state['batt'] -= 2.0
                            if debug_mode:
                                print(f"[t={self.sim_time:.0f}] üöÄ Sat {i} GOTO INC - Fuel -5.0, Batt -2.0")
                            

                # --- 3. CH·ª§P ·∫¢NH (TARGETS) ---
# --- 3. CH·ª§P ·∫¢NH (TARGETS) ---
                elif 0 <= act < self.n_targets:
                    state['batt'] -= 0.5
                    
                    if state['buffer'] >= self.buffer_max:
                        rewards[i] -= 5.0
                    else:
                        if act in self.global_captured_targets: rewards[i] -= 0.1
                        else:
                            tgt_pos = self.targets_ecef[act]
                            
                            # 1. T√≠nh Vector h∆∞·ªõng t·ªõi m·ª•c ti√™u
                            req_vec = tgt_pos - r_curr
                            dist = np.linalg.norm(req_vec)
                            req_vec /= (dist + 1e-9) # Vector ƒë∆°n v·ªã h∆∞·ªõng t·ªõi Target
                            
                            # 2. T√≠nh Vector Nadir (H∆∞·ªõng th·∫≥ng ƒë·ª©ng xu·ªëng ƒë·∫•t)
                            # r_curr l√† v·ªã tr√≠ v·ªá tinh (t·ª´ t√¢m Tr√°i ƒë·∫•t).
                            # Nadir l√† h∆∞·ªõng ng∆∞·ª£c l·∫°i c·ªßa r_curr (-r_curr)
                            nadir_vec = -r_curr / np.linalg.norm(r_curr)
                            
                            # 3. T√≠nh "G√≥c Nghi√™ng" (Off-Nadir Angle)
                            # L√† g√≥c gi·ªØa h∆∞·ªõng nh√¨n m·ª•c ti√™u v√† h∆∞·ªõng th·∫≥ng ƒë·ª©ng
                            dot_prod = np.dot(req_vec, nadir_vec)
                            off_nadir_angle = math.degrees(math.acos(np.clip(dot_prod, -1.0, 1.0)))
                            
                            # [REALISTIC] Gi·ªõi h·∫°n g√≥c nghi√™ng cho ph√©p (v√≠ d·ª•: t·ªëi ƒëa 30 ho·∫∑c 45 ƒë·ªô)
                            # N·∫øu m·ª•c ti√™u n·∫±m qu√° xa sang hai b√™n (nghi√™ng > 45 ƒë·ªô), camera kh√¥ng ch·ª•p n√©t ƒë∆∞·ª£c.
                            MAX_OFF_NADIR = 45.0 
                            
                            if off_nadir_angle > MAX_OFF_NADIR:
                                rewards[i] -= 0.1
                                if debug_mode: print(f"Sat {i} Target too oblique ({off_nadir_angle:.0f}¬∞ > 45¬∞)")
                            else:
                                # N·∫øu g√≥c nghi√™ng OK, th√¨ m·ªõi t√≠nh chuy·ªán xoay camera
                                cos = np.dot(state['bore_vec'], req_vec)
                                pointing_error = math.degrees(math.acos(np.clip(cos, -1.0, 1.0)))
                                max_turn = math.degrees(self.max_slew_rate) * self.decision_dt
                                
                                if pointing_error <= max_turn:
                                    state['bore_vec'] = req_vec
                                    if dist < 4000e3:
                                        self.global_captured_targets.add(act)
                                        state['buffer'] += 1
                                        rewards[i] += 5.0
                                        if debug_mode: print(f"[t={self.sim_time:.0f}] üì∏ Sat {i} CAPTURE T{act} (Off-Nadir: {off_nadir_angle:.1f}¬∞)")
                                    else: rewards[i] -= 0.1
                                else:
                                    # ƒêang xoay b√°nh ƒë√† ƒë·ªÉ h∆∞·ªõng t·ªõi m·ª•c ti√™u
                                    ratio = max_turn / pointing_error
                                    state['bore_vec'] = (1-ratio)*state['bore_vec'] + ratio*req_vec
                                    state['bore_vec'] /= np.linalg.norm(state['bore_vec'])

                # --- 4. DOWNLINK (TR·∫†M M·∫∂T ƒê·∫§T) ---
                elif self.n_targets <= act < self.n_targets + self.n_gs:
                    state['batt'] -= 0.5
                    gs_idx = act - self.n_targets
                    gs_pos = self.gs_ecef[gs_idx]
                    
                    # T√≠nh to√°n h∆∞·ªõng v·ªÅ tr·∫°m
                    req_vec = gs_pos - r_curr
                    dist = np.linalg.norm(req_vec) # Slant Range
                    req_vec /= (dist + 1e-9)
                    
                    cos = np.dot(state['bore_vec'], req_vec)
                    angle = math.degrees(math.acos(np.clip(cos, -1.0, 1.0)))
                    max_turn = math.degrees(self.max_slew_rate) * self.decision_dt
                    
                    # [LOGIC M·ªöI] ∆Øu ti√™n Downlink khi Buffer ƒë·∫ßy
                    is_full = (state['buffer'] >= self.buffer_max)
                    
                    # 1. Th∆∞·ªüng √Ω ch√≠ (Intent Reward)
                    # N·∫øu buffer ƒë·∫ßy m√† ch·ªçn Downlink -> Th∆∞·ªüng ngay l·∫≠p t·ª©c (ƒë·ªÉ n√≥ bi·∫øt l√† n√≥ ch·ªçn ƒë√∫ng ƒë∆∞·ªùng)
                    if is_full:
                        rewards[i] += 0.5 
                        if debug_mode:
                            print(f"[t={self.sim_time:.0f}] üì° Sat {i} BUFFER FULL - Intent to DOWNLINK (+0.5)")

                    if angle <= max_turn:
                        state['bore_vec'] = req_vec
                        
                        if state['buffer'] > 0:
                            # TR∆Ø·ªúNG H·ª¢P 1: Th√†nh c√¥ng (Trong v√πng ph·ªß s√≥ng)
                            if dist < 2800e3:
                                state['buffer'] -= 1
                                # Th∆∞·ªüng si√™u to kh·ªïng l·ªì
                                rewards[i] += 25.0 
                                if debug_mode: print(f"[t={self.sim_time:.0f}] üì° Sat {i} DOWNLINK SUCCESS (+25)!!!")
                            
                            # TR∆Ø·ªúNG H·ª¢P 2: ƒêang bay v·ªÅ (Trong v√πng ti·∫øp c·∫≠n)
                            # Th∆∞·ªüng d·∫´n ƒë∆∞·ªùng (Shaping Reward)
                            elif dist < 5000e3: 
                                # C√†ng g·∫ßn c√†ng nhi·ªÅu ƒëi·ªÉm
                                score = (5000e3 - dist) / (5000e3 - 2800e3) # 0.0 -> 1.0
                                
                                # N·∫øu Buffer ƒë·∫ßy, th∆∞·ªüng d·∫´n ƒë∆∞·ªùng x2 (ƒë·ªÉ n√≥ quy·∫øt t√¢m bay v·ªÅ)
                                multiplier = 2.0 if is_full else 0.5
                                rewards[i] += score * multiplier
                                
                                if debug_mode and i==0: 
                                    print(f"Sat {i} Homing to GS... (+{score*multiplier:.2f})")
                            else:
                                rewards[i] -= 0.1 # Qu√° xa
                                if debug_mode and i==0:
                                    print(f"Sat {i} Too far from GS ({dist/1e3:.0f} km) for Downlink.")
                        else:
                            rewards[i] -= 0.5 # Buffer tr·ªëng m√† ƒë√≤i Downlink
                            if debug_mode and i==0:
                                print(f"Sat {i} Buffer EMPTY! Cannot Downlink.")
                    else:
                        # ƒêang xoay v·ªÅ h∆∞·ªõng tr·∫°m
                        ratio = max_turn / angle
                        state['bore_vec'] = (1-ratio)*state['bore_vec'] + ratio*req_vec
                        state['bore_vec'] /= np.linalg.norm(state['bore_vec'])
                        rewards[i] += 0.05 # Th∆∞·ªüng nh·ªè v√¨ ƒëang xoay ƒë√∫ng h∆∞·ªõng
                        if debug_mode:
                            print(f"[t={self.sim_time:.0f}] üîÑ Sat {i} Turning to GS{gs_idx} (angle: {angle:.1f}¬∞)")
                
                else: 
                    state['batt'] -= 0.1 

            # Step Sim
            stop_time = self.sim_time + self.decision_dt
            self.scSim.ConfigureStopTime(int(macros.sec2nano(stop_time)))
            self.scSim.ExecuteSimulation()
            self.sim_time = stop_time
            
            if self.sim_time > 15000: dones = [True] * self.n_sats
            return self._get_all_obs(), rewards, dones, {}
    '''
    
    def step(self, actions, debug_mode=True):
            rewards = np.zeros(self.n_sats)
            dones = [False] * self.n_sats
            
            for i, action in enumerate(actions):
                sat = self.sats[i]
                state = self.states[i]
                act = int(action)
                
                # --- X·ª≠ l√Ω Pin/Ch·∫øt ---
                if state['batt'] <= 0 or state['fuel'] <= 0:
                    rewards[i] -= 10.0; dones[i] = True
                    print(f"[t={self.sim_time:.0f}] üíÄ Sat {i} DEAD Because " + ("BATTERY" if state['batt'] <= 0 else "FUEL"))
                    continue
                
                # L·∫•y vector hi·ªán t·∫°i
                v_curr = np.array(sat.hub.v_CN_NInit).flatten()
                r_curr = np.array(sat.hub.r_CN_NInit).flatten()
                
                # T√≠nh to√°n c√°c vector h∆∞·ªõng
                v_mag = np.linalg.norm(v_curr)
                v_dir = v_curr / (v_mag + 1e-9)
                
                # --- NH√ìM 1: S·∫†C PIN ---
                if act == self.ACT_CHARGE:
                    state['batt'] = min(self.batt_max, state['batt'] + 3.0)
                    rewards[i] += 0.1
                    if debug_mode and state['batt'] < 90:
                        print(f"[t={self.sim_time:.0f}] üîã Sat {i} CHARGE -> {state['batt']:.1f}%")

                # --- NH√ìM 2: THAY ƒê·ªîI QU·ª∏ ƒê·∫†O (ƒê√£ n√¢ng c·∫•p) ---
                elif act in [self.ACT_ALT_UP, self.ACT_ALT_DOWN, self.ACT_INC_UP, self.ACT_INC_DOWN]:
                    if state['fuel'] >= 2.0:
                        cost = 2.0
                        
                        # A. THAY ƒê·ªîI ƒê·ªò CAO (D√πng l·ª±c ƒë·∫©y vector th∆∞·ªùng)
                        if act == self.ACT_ALT_UP:
                            sat.hub.v_CN_NInit = v_curr + v_dir * 50.0 # TƒÉng t·ªëc 50m/s
                            if debug_mode: print(f"[t={self.sim_time:.0f}] üöÄ Sat {i} ALT UP (Boost)")
                        
                        elif act == self.ACT_ALT_DOWN:
                            sat.hub.v_CN_NInit = v_curr - v_dir * 50.0 # H√£m t·ªëc 50m/s
                            if debug_mode: print(f"[t={self.sim_time:.0f}] üîª Sat {i} ALT DOWN (Brake)")

                        # B. THAY ƒê·ªîI G√ìC NGHI√äNG (D√πng bi·∫øn ƒë·ªïi Kepler - Visual c·ª±c m·∫°nh)
                        elif act in [self.ACT_INC_UP, self.ACT_INC_DOWN]:
                            # 1. Chuy·ªÉn ƒë·ªïi r,v sang Kepler Elements (oe)
                            oe = orbitalMotion.rv2elem(self.planet_mu, r_curr, v_curr)
                            
                            old_i_deg = oe.i * macros.R2D
                            change_amount = 15.0 * macros.D2R # Thay ƒë·ªïi h·∫≥n 15 ƒë·ªô cho m√°u!
                            
                            if act == self.ACT_INC_UP:
                                # TƒÉng ƒë·ªô nghi√™ng -> Gi√∫p bao ph·ªß v√πng c·ª±c (Polar regions)
                                # Gi·ªõi h·∫°n max 90 ƒë·ªô (qu·ªπ ƒë·∫°o c·ª±c)
                                if oe.i < 85.0 * macros.D2R:
                                    oe.i += change_amount
                                    if debug_mode: print(f"[t={self.sim_time:.0f}] üìê Sat {i} INC UP: {old_i_deg:.0f}¬∞ -> {oe.i*macros.R2D:.0f}¬∞")
                                else:
                                    rewards[i] -= 0.5 # ƒê√£ k·ªãch kim, ko tƒÉng ƒë∆∞·ª£c n·ªØa
                            
                            elif act == self.ACT_INC_DOWN:
                                # Gi·∫£m ƒë·ªô nghi√™ng -> Gi√∫p bao ph·ªß v√πng x√≠ch ƒë·∫°o
                                # Gi·ªõi h·∫°n min 0 ƒë·ªô (qu·ªπ ƒë·∫°o x√≠ch ƒë·∫°o)
                                if oe.i > 5.0 * macros.D2R:
                                    oe.i -= change_amount
                                    if debug_mode: print(f"[t={self.sim_time:.0f}] üìê Sat {i} INC DOWN: {old_i_deg:.0f}¬∞ -> {oe.i*macros.R2D:.0f}¬∞")
                                else:
                                    rewards[i] -= 0.5

                            # 2. Chuy·ªÉn ng∆∞·ª£c l·∫°i r,v m·ªõi t·ª´ oe ƒë√£ s·ª≠a
                            r_new, v_new = orbitalMotion.elem2rv(self.planet_mu, oe)
                            
                            # 3. C·∫≠p nh·∫≠t cho v·ªá tinh
                            sat.hub.r_CN_NInit = r_new
                            sat.hub.v_CN_NInit = v_new
                            
                            # Ph·∫°t n·∫∑ng v√¨ ƒë·ªïi g√≥c nghi√™ng c·ª±c t·ªën k√©m
                            state['fuel'] -= 5.0 
                            state['batt'] -= 5.0

                        state['fuel'] -= cost
                        state['batt'] -= 2.0
                    else:
                        rewards[i] -= 0.5 # H·∫øt xƒÉng

                # --- NH√ìM 3: CH·ª§P ·∫¢NH (Logic c≈©) ---
                elif 0 <= act < self.n_targets:
                    # ... (Gi·ªØ nguy√™n logic ch·ª•p ·∫£nh c·ªßa b·∫°n) ...
                    # Copy l·∫°i ph·∫ßn ch·ª•p ·∫£nh t·ª´ code c≈© v√†o ƒë√¢y
                    state['batt'] -= 0.5
                    if act in self.global_captured_targets:
                        rewards[i] -= 0.1
                    else:
                        tgt_pos = self.targets_ecef[act]
                        req_vec = tgt_pos - r_curr
                        dist = np.linalg.norm(req_vec); req_vec /= dist
                        cos = np.dot(state['bore_vec'], req_vec)
                        angle = math.degrees(math.acos(np.clip(cos, -1.0, 1.0)))
                        max_turn = math.degrees(self.max_slew_rate) * self.decision_dt
                        
                        if angle <= max_turn:
                            state['bore_vec'] = req_vec
                            if state['buffer'] < self.buffer_max and dist < 4000e3:
                                self.global_captured_targets.add(act)
                                state['buffer'] += 1
                                rewards[i] += 5.0
                                if debug_mode: print(f"[t={self.sim_time:.0f}] üì∏ Sat {i} CAPTURE T{act}")
                            else: rewards[i] -= 0.1
                        else:
                            ratio = max_turn / angle
                            state['bore_vec'] = (1-ratio)*state['bore_vec'] + ratio*req_vec
                            state['bore_vec'] /= np.linalg.norm(state['bore_vec'])

                # --- NH√ìM 4: DOWNLINK (Logic c≈©) ---
                elif self.n_targets <= act < self.n_targets + self.n_gs:
                    # ... (Gi·ªØ nguy√™n logic downlink c·ªßa b·∫°n) ...
                    # Copy l·∫°i ph·∫ßn downlink t·ª´ code c≈© v√†o ƒë√¢y
                    state['batt'] -= 0.5
                    gs_idx = act - self.n_targets
                    gs_pos = self.gs_ecef[gs_idx]
                    req_vec = gs_pos - r_curr
                    dist = np.linalg.norm(req_vec); req_vec /= dist
                    cos = np.dot(state['bore_vec'], req_vec)
                    angle = math.degrees(math.acos(np.clip(cos, -1.0, 1.0)))
                    max_turn = math.degrees(self.max_slew_rate) * self.decision_dt
                    
                    if angle <= max_turn:
                        state['bore_vec'] = req_vec
                        if state['buffer'] > 0 and dist < 2500e3:
                            state['buffer'] -= 1
                            rewards[i] += 20.0
                            if debug_mode: print(f"[t={self.sim_time:.0f}] üì° Sat {i} DOWNLINK (+20)")
                        else: rewards[i] -= 0.1
                    else:
                        ratio = max_turn / angle
                        state['bore_vec'] = (1-ratio)*state['bore_vec'] + ratio*req_vec
                        state['bore_vec'] /= np.linalg.norm(state['bore_vec'])

                else:
                    state['batt'] -= 0.1

            # Step Sim & Check Done
            stop_time = self.sim_time + self.decision_dt
            self.scSim.ConfigureStopTime(int(macros.sec2nano(stop_time)))
            self.scSim.ExecuteSimulation()
            self.sim_time = stop_time
            
            if self.sim_time > 6000: dones = [True] * self.n_sats
                
            return self._get_all_obs(), rewards, dones, {}
    '''
# --- 4. TRAINER ---
def train_mission():
    N_SATS = 4
    N_TARGETS = 50
    # Env t·ª± t√≠nh Action Dim v√† Obs Dim
    env = BasiliskFullMissionEnv(n_sats=N_SATS, n_targets=N_TARGETS, viz=True)
    
    OBS_DIM = env.obs_dim
    ACT_DIM = env.action_dim
    GLOBAL_STATE_DIM = OBS_DIM * N_SATS
    EPOCHS = 20
    
    mappo_agent = MultiAgentActorCritic(OBS_DIM, GLOBAL_STATE_DIM, ACT_DIM)
    optimizer = optim.Adam(mappo_agent.parameters(), lr=1e-3)
    
    print(f"--- START MISSION TRAINING ---")
    print(f"Actions: {ACT_DIM} | Obs: {OBS_DIM}")
    print("Nhi·ªám v·ª•: S·∫°c Pin -> Ch·ª•p ·∫¢nh -> Bay v·ªÅ Tr·∫°m (Hanoi/NY/...) -> Downlink")
    
    for epoch in range(EPOCHS): # Demo 40 epochs
        obs_list = env.reset()
        ep_rewards = np.zeros(N_SATS)
        done = False
        
        # Buffer
        batch_obs, batch_gs, batch_acts, batch_rews = [], [], [], []
        
        while not done:
            actions_t = []
            global_state_t = np.concatenate(obs_list)
            
            # 1. Act
            for i in range(N_SATS):
                obs_t = torch.FloatTensor(obs_list[i]).unsqueeze(0)
                logits = mappo_agent.act(obs_t)
                dist = torch.distributions.Categorical(logits=logits)
                action = dist.sample()
                actions_t.append(action.item())
            
            # 2. Env Step (T·∫Øt debug khi train)
            next_obs, rewards, dones, _ = env.step(actions_t, debug_mode=True)
            
            # Store
            batch_obs.append(obs_list)
            batch_gs.append(global_state_t)
            batch_acts.append(actions_t)
            batch_rews.append(rewards)
            
            obs_list = next_obs
            ep_rewards += rewards
            done = any(dones) # Ch·ªâ c·∫ßn 1 sat ch·∫øt l√† reset epoch (ho·∫∑c all, t√πy logic)
        
        # 3. Update (Simple PG for demo brevity)
        optimizer.zero_grad()
        loss = 0
        
        # T√≠nh Discounted Returns
        returns = np.zeros_like(batch_rews)
        running_add = np.zeros(N_SATS)
        for t in reversed(range(len(batch_rews))):
            running_add = batch_rews[t] + 0.99 * running_add
            returns[t] = running_add
            
        # Loss Calculation
        for t in range(len(batch_obs)):
            g_state = torch.FloatTensor(batch_gs[t]).unsqueeze(0)
            target_val = torch.FloatTensor([np.mean(returns[t])]).unsqueeze(0)
            
            val_pred = mappo_agent.evaluate(g_state)
            val_loss = nn.MSELoss()(val_pred, target_val)
            
            act_loss = 0
            ent_loss = 0
            for i in range(N_SATS):
                obs = torch.FloatTensor(batch_obs[t][i]).unsqueeze(0)
                act = torch.tensor([batch_acts[t][i]])
                adv = returns[t][i] - val_pred.item()
                
                logits = mappo_agent.act(obs)
                dist = torch.distributions.Categorical(logits=logits)
                log_prob = dist.log_prob(act)
                
                act_loss += -log_prob * adv
                ent_loss += dist.entropy()
            
            # Loss t·ªïng h·ª£p: Actor + Critic - Entropy
            loss += act_loss + 0.5 * val_loss - 0.05 * (ent_loss/N_SATS)
            
        loss.backward()
        nn.utils.clip_grad_norm_(mappo_agent.parameters(), 0.5)
        optimizer.step()
        
        print(f"Epoch {epoch+1} | Reward: {np.mean(ep_rewards):.1f}")

    # --- DEMO PLAYBACK ---
    print("\n--- CH·∫†Y DEMO S·ª® M·ªÜNH ---")
    obs_list = env.reset()
    done = False
    try:
        while not done:
            actions_t = []
            for i in range(N_SATS):
                obs_t = torch.FloatTensor(obs_list[i]).unsqueeze(0)
                logits = mappo_agent.act(obs_t)
                # Greedy action
                action = torch.argmax(logits, dim=1)
                actions_t.append(action.item())
            
            # B·∫≠t Debug ƒë·ªÉ xem log S·∫°c/Ch·ª•p/Downlink
            next_obs, rewards, dones, _ = env.step(actions_t, debug_mode=True)
            obs_list = next_obs
            done = any(dones)
    except KeyboardInterrupt:
        print("Stop Demo.")

if __name__ == "__main__":
    train_mission()
    print("\n--- MISSION COMPLETE ---")